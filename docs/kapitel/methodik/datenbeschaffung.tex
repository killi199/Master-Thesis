\section{Datenbeschaffung}
\label{sec:datenbeschaffung}
% TODO MEINE SOFTWARE ZITIEREN! Sonst bin ich nicht besser als alle anderen und auch Probleme und Konfiguration darstellen -> steht in dem Paper smith_software_2016 wie zitiert werden soll? \autocite{richardson_beautifulsoup4_2024}
In diesem Abschnitt wird beschrieben wie das Skript zur Datenbeschaffung aus den einzelnen Quellen aufgebaut ist.
Es wird tqdm in der Version 4.66.5 verwendet, um den Fortschritt der Datenbeschaffung anzuzeigen \autocite{costa-luis_tqdm_2024}.
Die Datenbeschaffung wird in die einzelnen Quellen untergliedert.

Aus den Quellen \nameref{subsec:datenbeschaffung_git}, \nameref{subsec:datenbeschaffung_beschreibung}, \nameref{subsec:datenbeschaffung_cff} und \nameref{subsec:datenbeschaffung_bibtex} können zeitliche Informationen extrahiert werden, da diese in Git verwaltet werden.
Aus diesem Grund werden die Daten jeweils zu der Änderung der Quelle gespeichert.
Dabei ist die maximale Anzahl der Änderungen in die Vergangenheit auf 50 beschränkt, um die Laufzeit des Skripts zu begrenzen.

In \nameref{subsec:datenbeschaffung_cran} ist es nicht möglich die Änderungen in der Zeit zu betrachten.
In der \nameref{subsec:datenbeschaffung_pypi} Quelle ist es teilweise möglich die Änderungszeitpunkte zu erhalten, jedoch ist dies mit Kosten verbunden und erfordert eine andere Vorgehensweise als bei den anderen zeitlichen Daten, da diese nicht direkt aus Git extrahiert werden können.
Die beiden Quellen werden aus diesem Grund nur in der neusten Version betrachtet und enthalten keine Änderungshistorie.

\subsection{Git} % 2 Seiten
\label{subsec:datenbeschaffung_git}
Die Git Daten sind die grundlegenden Daten, welche für die weiteren Schritte benötigt werden.
Sämtliche anderen Quellen werden mit den Git Daten über den in \autoref{sec:abgleich} beschriebenen Prozess abgeglichen.
% TODO Beschreiben wie die Commits gezählt wurden.
% Git quick-stats erwähnen
% Zeit Möglich
% TODO auf meine verwendete Software eigehen z.B. git-quick-stats
% TODO gitpython==3.1.43, pytz==2024.2
\subsection{PyPI} % 2 Seiten
\label{subsec:datenbeschaffung_pypi}
% TODO erklären warum BigQuery nicht eingesetzt wird aktuell aber dennoch sinnvoll eingesetzt werden könnte bei anderen anforderungen (z.B. liste mit repo links auf github)
% TODO erklären warum die API verwendet wird und nicht nur die TOML beispielsweise ausgelesen wird -> habe ein pypi paket und brauche die GitHub URL
% TODO sagen warum beides also verifizierte Owner und Maintainer sowhl als auch die Daten aus der TOML abgefragt werden -> sind unterschiedliche Leute und werden unterschiedlich angegeben die einen dürfen sachen auf pypi machen die anderen werden in der toml angegeben und dürfen ggf. nichts in pypi machen
% Checken was verifizierte Nutzer im PyPI Universum bedeutet. Sind es nur verifizierte User die z.B. eine E-Mail hinterlegt haben oder sind es Nutzer die an dem Projekt arbeiten und von PyPI verifiziert sind? Falls es mehrwert hat diese Daten ebenfalls automatisch abfragen und auch in der MA beschreiben, was es nun ist und warum es Mehrwert hat oder auch nicht.
% TODO In MA beschreiben, warum oder warum nicht Mehrwert (PyPI Verifizierte Nutzer)
% TODO Sagen warum die Owner nicht berücksichtigt werden hatte dafür auch irgendwo eine Qulle -> es sind immer org.
% TODO erklären, dass ich den Namen des Betreuers brauche und nicht nur den Benutzernamen über die API und wie ich das gelöst habe mit einem WebScraper
% Zeit nicht möglich
% TODO erklären auf welchen branch ich untersuche ist es immer der Github default? oder nehme ich main? oder master? wie wird das entschieden?
% aiohttp==3.10.3, beautifulsoup4==4.12.3, spacy==3.7.6
\subsection{CRAN} % 2 Seiten
\label{subsec:datenbeschaffung_cran}
% Zeit nicht möglich
% TODO rpy2==3.5.16, aiohttp==3.10.3
\subsection{Beschreibung} % 2 Seiten
\label{subsec:datenbeschaffung_beschreibung}
% TODO Es werden alle Namen ausgegeben aber auch eben solche, die gar nichts mit dem Paket zu tun haben wie im fall von highr für CRAN: "Provides syntax highlighting for R source Code. Currently it supports LaTeX and HTML output. Source Code of other languages is supported via Andre Simon's highlight package (https://gitlab.com/saalen/highlight)." Es gibt noch weitere Beispiele z.B. in CRAN magrittr -> vllt eher ergebnis?
% Zeit Möglich
% spacy==3.7.6
\subsection{Citation File Format} % 2 Seiten
\label{subsec:datenbeschaffung_cff}
% TODO darauf eingehen, dass ich händisch aktuell geprüft habe ob das GH repo in cran oder pypi ist und daraus meine listen gebaut habe. Dies wäre aber auch automatisch möglich aber mit viel Aufwand und man bräuchte google big query für 100 pakete war dieser weg schneller außerdem gibt es auf PyPi mehrere Pakete die auf ein GitHub repo verlinken. Da müsste einiges beachtet werden um das genau zu machen für 100 war dies besser. Falls es für mehr gemacht werden sollte müsste das überdacht werden.
% TODO darauf eingehen wie die CFF geholt und verarbeitet wurde mit stars verknüpft und dann händisch pypi cran raus gesucht und den namen auf pypi
% TODO in der gegebenen Liste waren mehrere Repos auf GH doppelt mit unterschiedlichen Links. diese wurden entfernt.
% TODO sagen, dass nur die erste identifier-doi beschafft wird, da nur geguckt wird in den Ergebnissen ob überhaupt eine vorhanden ist
% Zeit Möglich
% pyyaml==6.0.2, cffconvert==2.0.0, jsonschema==4.23.0, pykwalify==1.8.0
% CFF und preferred citation getrennt
\subsection{\hologo{BibTeX}} % 2 Seiten
\label{subsec:datenbeschaffung_bibtex}
% Zeit Möglich
% bibtexparser @ git+https://github.com/sciunto-org/python-bibtexparser@main
